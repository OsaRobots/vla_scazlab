{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import gp\n",
    "import jax\n",
    "import glob \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n",
    "import os\n",
    "import probabilistic_probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_33.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_27.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_26.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_32.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_24.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_30.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_18.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_19.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_31.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_25.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_21.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_35.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_34.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_20.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_36.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_22.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_23.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_37.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_9.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_8.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_6.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_7.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_5.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_4.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_0.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_1.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_3.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_2.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_12.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_13.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_11.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_39.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_38.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_10.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_28.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_14.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_15.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_29.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_17.npy', '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/episode_test_16.npy']\n"
     ]
    }
   ],
   "source": [
    "vla_run_data = '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data'\n",
    "npys = glob.glob(vla_run_data + '/*.npy')\n",
    "print(npys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_semantic_entropy(prob_vector, center_bin_half_size=5):\n",
    "    # Compute the semantic entropy by splitting the prob_vector into three arrays\n",
    "    def entropy(p):\n",
    "        return np.sum(-p * np.log(p + 1e-10))\n",
    "    \n",
    "    center_index = len(prob_vector) // 2\n",
    "    center_bin = prob_vector[center_index - center_bin_half_size:center_index + center_bin_half_size]\n",
    "    left_bin = prob_vector[:center_index - center_bin_half_size]\n",
    "    right_bin = prob_vector[center_index + center_bin_half_size:]\n",
    "    \n",
    "    center_entropy = entropy(center_bin)\n",
    "    left_entropy = entropy(left_bin)\n",
    "    right_entropy = entropy(right_bin)\n",
    "    \n",
    "    return np.mean([center_entropy, left_entropy, right_entropy])\n",
    "\n",
    "def find_best_split(s_entropy, \n",
    "                    plot=True, \n",
    "                    label=\"\",\n",
    "                    n_splits=100):\n",
    "    # find the best split threshold for the semantic entropy\n",
    "\n",
    "    splits = np.linspace(1e-10, s_entropy.max(), n_splits)\n",
    "    split_mses = []\n",
    "    \n",
    "    for split in splits:\n",
    "        low_idxs, high_idxs = s_entropy < split, s_entropy >= split\n",
    "        \n",
    "        if not any(low_idxs) or not any(high_idxs):\n",
    "            split_mses.append(float('inf'))\n",
    "            continue\n",
    "            \n",
    "        low_mean = np.mean(s_entropy[low_idxs])\n",
    "        high_mean = np.mean(s_entropy[high_idxs])\n",
    "        \n",
    "        mse = np.sum((s_entropy[low_idxs] - low_mean)**2) + np.sum((s_entropy[high_idxs] - high_mean)**2)\n",
    "        split_mses.append(mse)\n",
    "    \n",
    "    split_mses = np.array(split_mses)\n",
    "    best_split = splits[np.argmin(split_mses)]\n",
    "    \n",
    "    if plot:\n",
    "        plt.plot(splits, split_mses, label=label)\n",
    "        plt.xlabel('Split Thresholds')\n",
    "        plt.ylabel('Mean Squared Error')\n",
    "        plt.title('MSE vs Split Threshold')\n",
    "        if label:\n",
    "            plt.legend()\n",
    "    \n",
    "    return best_split\n",
    "\n",
    "def binarize_s_entropy(s_entropy, threshold):\n",
    "    return (s_entropy >= threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_se_into_data(save_dir, npy_paths, verbose=False):\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        \n",
    "    for num_trial in range(len(npy_paths)):\n",
    "        data_path = npy_paths[num_trial]\n",
    "        name = data_path.split('/')[-1]\n",
    "        if verbose:\n",
    "            print(name, save_dir)\n",
    "        data = np.load(data_path, allow_pickle=True)\n",
    "        for dct in data:\n",
    "            ses = []\n",
    "            probs = dct['probs']\n",
    "            for prob_vec in probs:\n",
    "                se = compute_semantic_entropy(prob_vec)\n",
    "                ses.append(se)\n",
    "            dct['se'] = ses\n",
    "        s_path = save_dir + '/' + name\n",
    "        if verbose:\n",
    "            print(s_path)\n",
    "        np.save(s_path, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode_test_33.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_33.npy\n",
      "episode_test_27.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_27.npy\n",
      "episode_test_26.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_26.npy\n",
      "episode_test_32.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_32.npy\n",
      "episode_test_24.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_24.npy\n",
      "episode_test_30.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_30.npy\n",
      "episode_test_18.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_18.npy\n",
      "episode_test_19.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_19.npy\n",
      "episode_test_31.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_31.npy\n",
      "episode_test_25.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_25.npy\n",
      "episode_test_21.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_21.npy\n",
      "episode_test_35.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_35.npy\n",
      "episode_test_34.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_34.npy\n",
      "episode_test_20.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_20.npy\n",
      "episode_test_36.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_36.npy\n",
      "episode_test_22.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_22.npy\n",
      "episode_test_23.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_23.npy\n",
      "episode_test_37.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_37.npy\n",
      "episode_test_9.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_9.npy\n",
      "episode_test_8.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_8.npy\n",
      "episode_test_6.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_6.npy\n",
      "episode_test_7.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_7.npy\n",
      "episode_test_5.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_5.npy\n",
      "episode_test_4.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_4.npy\n",
      "episode_test_0.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_0.npy\n",
      "episode_test_1.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_1.npy\n",
      "episode_test_3.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_3.npy\n",
      "episode_test_2.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_2.npy\n",
      "episode_test_12.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_12.npy\n",
      "episode_test_13.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_13.npy\n",
      "episode_test_11.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_11.npy\n",
      "episode_test_39.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_39.npy\n",
      "episode_test_38.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_38.npy\n",
      "episode_test_10.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_10.npy\n",
      "episode_test_28.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_28.npy\n",
      "episode_test_14.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_14.npy\n",
      "episode_test_15.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_15.npy\n",
      "episode_test_29.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_29.npy\n",
      "episode_test_17.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_17.npy\n",
      "episode_test_16.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se/episode_test_16.npy\n"
     ]
    }
   ],
   "source": [
    "save_dir = '/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se'\n",
    "vla_run_data = '/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data'\n",
    "npy_paths = glob.glob(vla_run_data + '/*.npy')\n",
    "get_se_into_data(save_dir=save_dir, npy_paths=npy_paths, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode_validate_8.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/val_finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/val_finetune_vla_data_se/episode_validate_8.npy\n",
      "episode_validate_9.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/val_finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/val_finetune_vla_data_se/episode_validate_9.npy\n",
      "episode_validate_2.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/val_finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/val_finetune_vla_data_se/episode_validate_2.npy\n",
      "episode_validate_3.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/val_finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/val_finetune_vla_data_se/episode_validate_3.npy\n",
      "episode_validate_1.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/val_finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/val_finetune_vla_data_se/episode_validate_1.npy\n",
      "episode_validate_0.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/val_finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/val_finetune_vla_data_se/episode_validate_0.npy\n",
      "episode_validate_4.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/val_finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/val_finetune_vla_data_se/episode_validate_4.npy\n",
      "episode_validate_5.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/val_finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/val_finetune_vla_data_se/episode_validate_5.npy\n",
      "episode_validate_7.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/val_finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/val_finetune_vla_data_se/episode_validate_7.npy\n",
      "episode_validate_6.npy /Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/val_finetune_vla_data_se\n",
      "/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/val_finetune_vla_data_se/episode_validate_6.npy\n"
     ]
    }
   ],
   "source": [
    "save_dir_val = '/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/val_finetune_vla_data_se'\n",
    "npy_paths_val = glob.glob('/Users/jeremiahetiosaomeike/Downloads/vla_finetuned_run_data/validate' + '/*.npy')\n",
    "get_se_into_data(save_dir=save_dir_val, npy_paths=npy_paths_val, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probe_vars(data_dir):\n",
    "    new_npys = glob.glob(data_dir + '/*.npy')\n",
    "    ses = []\n",
    "    hs_bgs = []\n",
    "    hs_pgs = []\n",
    "    for num_trial in range(len(new_npys)):\n",
    "        data_path = new_npys[num_trial]\n",
    "        data = np.load(data_path, allow_pickle=True)\n",
    "        for dct in data:\n",
    "            hs_bgs.append(dct['hidden_state_before_gen'])\n",
    "            hs_pgs.append(dct['hidden_state_post_gen'])\n",
    "            ses.append(dct['se'])\n",
    "    \n",
    "    return np.asarray(ses), np.asarray(hs_bgs), np.asarray(hs_pgs)\n",
    "\n",
    "data_dir = '/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/finetune_vla_data_se'\n",
    "data_dir_val = '/Users/jeremiahetiosaomeike/research_projects/vla/LIBERO/probes/val_finetune_vla_data_se'\n",
    "ses, hs_bgs, hs_pgs = get_probe_vars(data_dir)\n",
    "# ses_val, hs_bgs_val, hs_pgs_val = get_probe_vars(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Entropy Shape: (1438, 7) \n",
      " Hidden States Before Generation Shape: (1438, 1, 4096) \n",
      " Hidden States Post Generation Shape: (1438, 1, 4096)\n"
     ]
    }
   ],
   "source": [
    "print(f'Semantic Entropy Shape: {ses.shape} \\n Hidden States Before Generation Shape: {hs_bgs.shape} \\n Hidden States Post Generation Shape: {hs_pgs.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_bgs = hs_bgs.squeeze(axis=1)\n",
    "hs_pgs = hs_pgs.squeeze(axis=1)\n",
    "\n",
    "# hs_bgs_val = hs_bgs_val.squeeze(axis=1)\n",
    "# hs_pgs_val = hs_pgs_val.squeeze(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUCCESS_TRIALS_TRAIN = {\n",
    "#     0: 1, 1: 0, 2: 0, 3: 1, 4: 0, 5: 0, 6: 0, 7: 1, \n",
    "#     8: 0, 9: 1, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0,\n",
    "#     16: 0, 17: 1, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0,\n",
    "#     24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0, 30: 1, 31: 1,\n",
    "#     32: 1, 33: 1, 34: 1, 35: 1, 36: 1, 37: 1, 38: 1, 39: 1\n",
    "# }\n",
    "\n",
    "# SUCCESS_TIMESTEPS_TRAIN = {\n",
    "#     0: 23, 3: 21, 7: 23, 9: 25, 17: 27, 30: 32, 31: 41,\n",
    "#     32: 25, 33: 38, 34: 24, 35: 31, 36: 22, 37: 21, 38: 16, 39: 16\n",
    "# }\n",
    "\n",
    "ses = np.asarray(ses)\n",
    "hs_bgs = np.asarray(hs_bgs)\n",
    "hs_pgs = np.asarray(hs_pgs)\n",
    "thresholds = {}\n",
    "avg_ses_pos = ses[:, :3].mean(axis=1)\n",
    "best_thresh_avg_pos_ses = find_best_split(avg_ses_pos, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 4096)\n",
      "(256, 4096)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'8'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 54\u001b[0m\n\u001b[1;32m     52\u001b[0m num_helps_bgs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcount_nonzero(binarized_mean_label_query_pred_bgs)\n\u001b[1;32m     53\u001b[0m num_helps_pgs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcount_nonzero(binarized_mean_label_query_pred_pgs)\n\u001b[0;32m---> 54\u001b[0m \u001b[43maverage_queries_dict_bgs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnpy_path_num\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mappend(num_helps_bgs)\n\u001b[1;32m     55\u001b[0m average_queries_dict_pgs[npy_path_num]\u001b[38;5;241m.\u001b[39mappend(num_helps_pgs)\n",
      "\u001b[0;31mKeyError\u001b[0m: '8'"
     ]
    }
   ],
   "source": [
    "SUCCESS_TRIALS_VAL = {\n",
    "    0: 1, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 1, 7: 1, \n",
    "    8: 1, 9: 1}\n",
    "\n",
    "average_queries_dict_bgs = {0: [], 1: [], 2: [], 3: [], 4: [], 5: [], 6: [], 7: [], 8: [], 9: []}\n",
    "average_queries_dict_pgs = {0: [], 1: [], 2: [], 3: [], 4: [], 5: [], 6: [], 7: [], 8: [], 9: []}\n",
    "\n",
    "for npy_path in glob.glob(data_dir_val + '/*.npy'):\n",
    "    npy_path_num = int(npy_path.split('.')[0][-1])\n",
    "    data = np.load(npy_path, allow_pickle=True) \n",
    "    ses_val = []\n",
    "    hs_bgs_val = []\n",
    "    hs_pgs_val = []\n",
    "\n",
    "    for step in data:\n",
    "        ses_val.append(step['se'])\n",
    "        hs_bgs_val.append(step['hidden_state_before_gen'])\n",
    "        hs_pgs_val.append(step['hidden_state_post_gen'])\n",
    "\n",
    "    ses_val = np.asarray(ses_val)\n",
    "    query_hs_bgs_val = np.asarray(hs_bgs_val).squeeze(axis=1)\n",
    "    query_hs_pgs_val = np.asarray(hs_pgs_val).squeeze(axis=1)\n",
    "\n",
    "    avg_ses_pos_val = ses_val[:, :3].mean(axis=1)\n",
    "    gt_labels_val = binarize_s_entropy(avg_ses_pos_val, best_thresh_avg_pos_ses)\n",
    "\n",
    "    num_iters = 10\n",
    "    num_data = 256\n",
    "\n",
    "    for _ in range(num_iters):\n",
    "        # Sample random indexes \n",
    "        random_idxs = np.random.choice(len(avg_ses_pos), num_data, replace=False)\n",
    "        sampled_avg_ses = avg_ses_pos[random_idxs] # semantic entropies here \n",
    "\n",
    "        sampled_hs_bgs = np.asarray(hs_bgs)[random_idxs] # hidden states before generation\n",
    "        sampled_hs_pgs = np.asarray(hs_pgs)[random_idxs] # hidden states post generation\n",
    "        \n",
    "        label_obs = binarize_s_entropy(sampled_avg_ses, best_thresh_avg_pos_ses) # binarized labels \n",
    "\n",
    "        measures_hs_bgs = probabilistic_probe.gpp(query_hs_bgs_val, sampled_hs_bgs, label_obs)\n",
    "        measures_hs_pgs = probabilistic_probe.gpp(query_hs_pgs_val, sampled_hs_pgs, label_obs)\n",
    "\n",
    "        mean_label_query_pred_bgs = measures_hs_bgs['bernoulli_mu']\n",
    "        mean_label_query_pred_pgs = measures_hs_pgs['bernoulli_mu']\n",
    "\n",
    "        binarized_mean_label_query_pred_bgs = (mean_label_query_pred_bgs >= .5).astype(int)\n",
    "        binarized_mean_label_query_pred_pgs = (mean_label_query_pred_pgs >= .5).astype(int)\n",
    "\n",
    "        num_helps_bgs = np.count_nonzero(binarized_mean_label_query_pred_bgs)\n",
    "        num_helps_pgs = np.count_nonzero(binarized_mean_label_query_pred_pgs)\n",
    "        average_queries_dict_bgs[npy_path_num].append(num_helps_bgs)\n",
    "        average_queries_dict_pgs[npy_path_num].append(num_helps_pgs)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "libero_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
