{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import gp\n",
    "import jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gp_classifier(X, y, params=None):\n",
    "    # predict binarized semantic entropy labels using gp classifier\n",
    "    # x should be (n_samples, hidden_dim) and y should be (n_samples,) binary labels\n",
    "    \n",
    "    #TODO: can probably just tune these hyperparams using MAP estimate or something like that \n",
    "    if params is None:\n",
    "        params = {\n",
    "            'constant': 0.0,\n",
    "            'signal_variance': 6.0,\n",
    "            'alpha_eps': 0.1,\n",
    "            'strength': 5.0,\n",
    "            'intercept_scaling': 1.0\n",
    "        }\n",
    "    \n",
    "    # gp funcs \n",
    "    mean_func = gp.constant_mean\n",
    "    cov_func = gp.cosine_kernel\n",
    "    \n",
    "    # negative log likelihood\n",
    "    nll = gp.beta_gp_nll(\n",
    "        mean_func=mean_func,\n",
    "        cov_func=cov_func,\n",
    "        params=params,\n",
    "        x_train=X,\n",
    "        y_train=y\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'mean_func': mean_func,\n",
    "        'cov_func': cov_func,\n",
    "        'params': params,\n",
    "        'nll': nll\n",
    "    }\n",
    "\n",
    "def predict_entropy(model, X_test):\n",
    "    # predict entropy for test data\n",
    "    # X_test should be (n_samples, hidden_dim) and model should be the output of train_gp_classifier\n",
    "    predictions = gp.beta_gp_predict(\n",
    "        mean_func=model['mean_func'],\n",
    "        cov_func=model['cov_func'],\n",
    "        params=model['params'],\n",
    "        x_query=X_test,\n",
    "        var_only=True\n",
    "    )\n",
    "    \n",
    "    # get latent function since out of distribution\n",
    "    mu, var = gp.get_latent_gp(predictions)\n",
    "    \n",
    "    # probs and quantiles\n",
    "    probs, quantiles = gp.get_beta_quantiles(predictions, q=0.025)\n",
    "    \n",
    "    return {\n",
    "        'probabilities': probs,\n",
    "        'confidence_intervals': quantiles,\n",
    "        'latent_mean': mu,\n",
    "        'latent_var': var\n",
    "    }\n",
    "\n",
    "def train_all_action_dimensions(hidden_states_dict, entropies_dict):\n",
    "    # train the GP classifier for each action dimension\n",
    "    models = {}\n",
    "\n",
    "    for action_dim in hidden_states_dict.keys():\n",
    "        X = hidden_states_dict[action_dim]\n",
    "        y = entropies_dict[action_dim]\n",
    "        model = train_gp_classifier(X, y)\n",
    "        models[action_dim] = model\n",
    "    \n",
    "    return models \n",
    "\n",
    "\"\"\"\n",
    "# assumes in dictionaries like:\n",
    "hidden_states_dict = {\n",
    "    0: X_0,  # hidden states for action dimension 0\n",
    "    1: X_1,  # hidden states for action dimension 1\n",
    "    ...\n",
    "    6: X_6   # hidden states for action dimension 6\n",
    "}\n",
    "\n",
    "entropies_dict = {\n",
    "    0: y_0,  # semantic entropy or probability values for action dimension 0\n",
    "    1: y_1,  # semantic entropy or probability values for action dimension 1\n",
    "    ...\n",
    "    6: y_6   # semantic entropy or probability values for action dimension 6\n",
    "}\n",
    "\n",
    "# train models for all action dimensions\n",
    "results = train_all_action_dimensions(hidden_states_dict, entropies_dict)\n",
    "\n",
    "# TODO: metrics?\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "libero_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
